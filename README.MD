# Run llama2 locally via huggingface `transformers`
